{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0914f84d",
   "metadata": {},
   "source": [
    "### Part 3: Modeling\n",
    "\n",
    "The goal of this project is to create a model that can predict what type of common element of computer user interfaces an image is from a hand-written drawing (buttons, toggles, windows, etc.).\n",
    "\n",
    "This is part 3 of that project, and covers building models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621ebe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grahamsmith/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9fe3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table('/Users/grahamsmith/Documents/SpringboardWork/Springboard/UIsketch.parquet')\n",
    "df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4349dc",
   "metadata": {},
   "source": [
    "Set the labels to be numeric to make modeling easier (note: this should have been done in the preprocessing step but I forgot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c72bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set(df['label'])\n",
    "dummies = list(range(len(labels)))\n",
    "labeldf = pd.DataFrame([labels, dummies]).T\n",
    "df['label'] = df['label'].replace(list(labeldf.iloc[:,0]),labeldf.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415219aa",
   "metadata": {},
   "source": [
    "This table is so that the labels can be easily mapped back to the numbers for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75c4717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>label</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alert</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>menu</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>radio_button_unchecked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text_field</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dropdown_menu</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chip</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>switch_disabled</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>button</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>checkbox_checked</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>radio_button_checked</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data_table</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text_area</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>grid_list</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>checkbox_unchecked</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>switch_enabled</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>card</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>floating_action_button</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tooltip</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0   1\n",
       "0                   slider   0\n",
       "1                    label   1\n",
       "2                    alert   2\n",
       "3                    image   3\n",
       "4                     menu   4\n",
       "5   radio_button_unchecked   5\n",
       "6               text_field   6\n",
       "7            dropdown_menu   7\n",
       "8                     chip   8\n",
       "9          switch_disabled   9\n",
       "10                  button  10\n",
       "11        checkbox_checked  11\n",
       "12    radio_button_checked  12\n",
       "13              data_table  13\n",
       "14               text_area  14\n",
       "15               grid_list  15\n",
       "16      checkbox_unchecked  16\n",
       "17          switch_enabled  17\n",
       "18                    card  18\n",
       "19  floating_action_button  19\n",
       "20                 tooltip  20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e42882",
   "metadata": {},
   "source": [
    "Do the train/test split that we figured out in the pre-processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b2f0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 80% of images within each class aka label.\n",
    "train = df.groupby('label', group_keys=False).apply(lambda x: x.sample(frac=0.8))\n",
    "# Get the indicies of the images not in the test set and assign those images to the test set.\n",
    "testind = list(set(df.index) - set(train.index))\n",
    "test = df.iloc[testind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9e278",
   "metadata": {},
   "source": [
    "Unfortunately, my computer kept crashing, so I could only get any of the following models to run by cutting out 70% of my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small = train.groupby('label', group_keys=False).apply(lambda x: x.sample(frac=0.3))\n",
    "x_train = train_small.loc[:, train_small.columns != 'label']\n",
    "y_train = train_small['label']\n",
    "x_test = test.loc[:, test.columns != 'label']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d86e6",
   "metadata": {},
   "source": [
    "The first model I attempted was XGBoost, because it has ridge regression built in and I figured with so many parameters some would probably be reduced to 0. It is also faster than multiple logistic regression by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "912a7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "           (\"scale\", StandardScaler())]\n",
    ")\n",
    "\n",
    "num_cols = x_train.select_dtypes(include=\"number\").columns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "145205e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "print(type(xgb_cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a59a384",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grahamsmith/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/grahamsmith/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Init classifier\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "# Fit\n",
    "xgb_cl.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "preds = xgb_cl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "355336b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41496598639455784"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a62576",
   "metadata": {},
   "source": [
    "This initial XGBoost model has an overall accuracy score of 42%. This is only slightly better than the ~40% we were getting with KNN in the preprocessing step.\n",
    "\n",
    "Even with cutting down my data drammatically it still took more then 12 hours to run this model, so I decided against trying to tune the parameters and instead moved on to my second method LightGBM. I chose it primarily because it is much faster than XGBoost with many of the same benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "254e3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna  # pip install optuna\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {}  # to be filled in later\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = lgbm.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric=\"binary_logloss\",\n",
    "            early_stopping_rounds=100,\n",
    "        )\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_scores[idx] = preds\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "002a6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1765bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Init classifier\n",
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "\n",
    "# Init Grid Search\n",
    "grid_cv = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring=\"roc_auc\")\n",
    "\n",
    "# Fit\n",
    "_ = grid_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ee5700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b913808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's multi_logloss: 0.37064\tvalid_0's multi_logloss: 2.18407\n",
      "[40]\ttraining's multi_logloss: 0.0915149\tvalid_0's multi_logloss: 2.09388\n",
      "[60]\ttraining's multi_logloss: 0.0471361\tvalid_0's multi_logloss: 2.15989\n",
      "[80]\ttraining's multi_logloss: 0.0383709\tvalid_0's multi_logloss: 2.26604\n",
      "[100]\ttraining's multi_logloss: 0.0364348\tvalid_0's multi_logloss: 2.3888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.09, max_depth=-5, random_state=42)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(learning_rate=0.09, max_depth=-5, random_state=42)\n",
    "model.fit(x_train,y_train, eval_set=[(x_test,y_test), (x_train,y_train)],\n",
    "          verbose=20, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88d29695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.9744\n",
      "Testing accuracy 0.6340\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy {:.4f}'.format(model.score(x_train,y_train)))\n",
    "print('Testing accuracy {:.4f}'.format(model.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84e916",
   "metadata": {},
   "source": [
    "Oh ho! Now we're getting somewhere. LightGBM was both considerably faster (took only a breezy 4 hours to run!) but was also considerably more accurate, hitting 63% on the test set.\n",
    "\n",
    "While I'm going to leave the project here for the sake of expediancy, I will note that if I had more time a Convolutional Neural Network would almost certainly be more accurate than the models I've used here. Sadly 63% is still a far cry from good enough to replace a human at the task of identifying the images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
